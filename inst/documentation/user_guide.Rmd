---
title: "rEDM User Guide"
author: "Hao Ye"
date: "April 10, 2015"
output:
  html_document: 
    toc: true
    number_sections: true
    css: styles.css
bibliography: rEDM_refs.bib
---
# Introduction
This file is designed to serve as an introductory user guide to **rEDM**, an R package for Empirical Dynamic Modeling (EDM).

# Installation
rEDM is an **Rcpp** package, meaning that it contains both **C++** and **R** code. Because the C++ code needs to be compiled prior to usage, we present several different options for obtaining and installing the rEDM package, depending on your familiarity with R's package system.  

## Prerequisites

### R version
rEDM is compatible with **R 3.1.0+**; please ensure you have an up-to-date copy of **R**, which you can download from [CRAN](http://cran.r-project.org/). (For Mac users, please make sure that you have the version built for **OS X Mavericks**.)

### Operating System
We have tested rEDM on **Mac OS X 10.9+** or **Windows 7+ (32-bit or 64-bit)**. Collaborators have also gotten rEDM working on **Linux** (Amazon EC2) by compiling from source (see below).

### Rcpp
rEDM requires **Rcpp (0.11.2+)** to be installed. Please follow the normal [instructions](http://www.cookbook-r.com/Basics/Installing_and_using_packages/) to install the Rcpp package first.

## Precompiled Binary Version
Precompiled versions can be downloaded from this [Github repository](https://github.com/ha0ye/rEDM-binary). Please be sure to download the latest version (0.2.4 as of April 6, 2015). Note that you want the entire package file (with .tgz or .zip extension) and not the folder with all of the package contents (if you click on the file, there should be a link to "view the full file", which should initiate a downlaod. After downloading, there is no need to extract the contents, as R expects a single package file, rather than a folder.

To install the precompiled binary package, use the standard R command (`install.packages`) as below, replacing `***` with the name of the package file. (You will need to either give the complete path, or put the package file in R's working directory.)

```{r, eval = FALSE}
install.packages("***", type = "source", repos = NULL)
```

## Source Version
The raw source can be downloaded from my Github repository [here](https://github.com/ha0ye/rEDM). If you are familiar with using Git with Rstudio projects, you can go ahead and clone it directly. Otherwise, it is possible to install it using functions from the **devtools** package:

```{r, eval = FALSE}
library(devtools)
install_github("ha0ye/rEDM")
```

Note that this method requires **Git** to be installed, along with a **C++11** compiler, in addition to **Rcpp**. We have successfully tested this method of installation using both **Rtools 3.1** for Windows (a set of developer tools including c/c++ compilers) as well as **XCode 5.0+** for Macintosh.

# Examples

## Data Input

The **rEDM** functions are designed to accept data in common R data formats, namely vectors, matrices, and data.frames. Depending on the specific function, one or the other data type is preferred. Please see the documentation associated with individual functions for more details.

Missing data can be input using either `NA` or `NAN`. The program will automatically ignore such missing values as appropriate. For instance, simplex projection will not select nearest neighbors if any of the state vector coordinates is missing or if the corresponding target value is missing.

Note that when there is no observed target value, it is still possible to predict from a given state vector, if it has no missing values. Thus, it is possible to use the software to forecast ahead from an observed state into an unbserved future. This can be done simply by substituting `NA` or `NAN` for unknown future values. However, be aware that the performance metrics will be computed so as to ignore such predictions (since there are no observed values to compare against). Thus, the statistics (e.g., $\rho$, MAE, RMSE) may be computed based on fewer predictions than those actually made by the software.

## General Parameters

Many of the functions in **rEDM** are designed around the same prediction engine, and so share many of the following parameters. Please see the documentation associated with individual functions to verify which parameters are applicable as well as the default values (which can change from function to function)

* lib
    + a 2-column matrix (or 2-element vector) where each row specifies the portions of the time series to use for attractor reconstruction (i.e., the set of vectors that can be selected as nearest neighbors)
    + e.g., `(1, n)` specifies that the first n *rows* (from 1 to n) of data are a contiguous time series block, each point of which can be used to construct state vectors
    + by default, lib uses the entire input as a single contiguous segment
* pred
    + (same format as lib, but specifes the portions of the time series to make predictions for)
* norm_type
    + `"L2 norm"` (default) or `"L1 norm"`: specifies which distance metric to use when doing calculations
    + `"L2 norm"` is the standard Euclidean distance, where the distance between a vector $\vec{x} = \langle x_1, x_2, \dots, x_n \rangle$ and $\vec{y} = \langle y_1, y_2, \dots, y_n \rangle$ is computed as $\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^x + \dots + (x_n - y_n)^2}$.
    + `"L1 norm"` is the Manhattan norm (also known as taxicab distance), where the distance between a vector $\vec{x} = \langle x_1, x_2, \dots, x_n \rangle$ and $\vec{y} = \langle y_1, y_2, \dots, y_n \rangle$ is computed as $|x_1 - y_1| + |x_2 - y_2| + \dots + |x_n - y_n|$.
* E
    + the embedding dimension to use for attractor reconstruction
* tau
    + the lag to use for attractor reconstruction
    + by default, tau is set to `1`
* tp
    + the prediction horizon (how many steps ahead to make forecasts)
    + (negative values will also work)
* num_neighbors
    + the number of neighbors to use
    + `"e+1"`, `"E+1"`, `"e + 1"`, and `"E + 1"` will all peg this parameter to be `E+1` for each run
    + values less than 1 will use all possible neighbors
* theta
    + the nonlinear tuning parameter (for use with S-maps) that adjusts how distance is factored into computation of the local linear map (`0` corresponds to a globally linear map, while values greater than 0 correspond to nonlinear models where the local linear map changes as a function of state-space)
* stats_only
    + `TRUE` (default) or `FALSE`: specifies whether the output should just contain statistics of the predictions, or also contain all the predictions that were made
* exclusion_radius
    + `exclusion_radius` sets the threshold whereby all vectors with time indices too close to the predictee will be excluded from being considered nearest neighbors
    + e.g., `1` means that vectors must have an associated time index more than 1 away from potential nearest neighbors
    + by default, exclusion_radius is set to NULL (turning this filtering off)
* epsilon
    + `epsilon` sets the threshold whereby all vectors with distance too far away from the predictee will be excluded from being considered nearest neighbors
    + e.g., `2` means that vectors must have be within a distance of 2 from potential nearest neighbors
    + by default, epsilon is set to NULL (turning this filtering off)
* silent
    + `TRUE` or `FALSE` (default): specifies whether to suppress warning messages from being printed to the R console
* save_smap_coefficients
    + `TRUE` or `FALSE` (default): specifies whether to include a table of s-map coefficients with the output
    + (note that setting this to `TRUE` forces the full output as if `stats_only = FALSE`)

## Simplex Projection

**Simplex Projection** is a nearest neighbor forecasting method [see @Sugihara_1990]. It is typically applied as a simple test for estimating the optimal *embedding dimension* for a time-series. We demonstrate this in the following example.  

First, we load the data and look at the format.

```{r}
library(rEDM)
data(sockeye_returns)
head(sockeye_returns)
```

We can see that the data is in wide format with a time column (`year`) and additional columns representing time series of returns for different stocks within the dataset. For now, we'll just look at doing an analysis based on one of the stocks.

We being by running simplex projection to identify the optimal embedding dimension. Note that we let many of the parameters to the `simplex` function be default values (e.g., $\tau = 1$, $\text{tp} = 1$). The default values for the embedding dimension, $E$, range from $1$ to $10$, and so the output will allow us to determine which embedding dimension best unfolds the attractor.

Initially, we'd like to use leave-one-out cross-validation over the entire time series, so the `lib` and `pred` arguments should be set appropriately. By setting `lib = c(1, length(ts))`, we indicate that the data points beginning with at row `1` of the data and ending in row `length(ts)` form a time series that we are using for attractor reconstruction. Similarly, we set `pred` in the same way. (These are also the default values if not supplied to `simplex`.)

Note that the code automatically detects this overlap and outputs a warning message to indicate that it will use leave-one-out cross-validation.

```{r}
ts <- sockeye_returns$Early_Stuart
lib <- c(1, length(ts))
pred <- c(1, length(ts))
simplex_output <- simplex(ts, lib, pred)
```

The results are a simple data.frame with columns for each of the model parameters and forecast statistics, and rows for each run of the model. In this case, there is one run for each value of $E$, so we can simply plot $E$ against $\rho$, the correlation between observed and predicted values:

```{r}
par(mar = c(4,4,1,1))
plot(simplex_output$E, simplex_output$rho, type = "l", 
     xlab = "Embedding Dimension (E)", ylab = "Forecast Skill (rho)")
```

## S-map

**S-map** is a forecasting method that also relies on the principle of attractor reconstruction. However, it has a nonlinear tuning parameter, $\theta$, that affects how weights change with distance in state space. When $\theta = 0$, all weights are equal, and the S-map is identical to an autoregressive model; values of $\theta$ above $0$ give greater weight to nearby points in the state space, thereby accommodating nonlinear behavior by allowing the local linear map to vary with state-space. Thus, varying $\theta$ allows us to compare equivalent linear and nonlinear models as a test for nonlinear dynamics (after first using **simplex projection** to estimate the optimal *embedding dimension* for a time-series.) We demonstrate this in the following example.

Following from the previous example, we set `E = 5` based on the results from simplex projection. Again, note that we allow many of the parameters to the `s_map` function take on default values (e.g., $\tau = 1$, $\text{tp} = 1$). If we had changed these for simplex projection, we would want to propagate those same values for the `s_map`. The default values for the nonlinear tuning parameter, $\theta$, range from $0$ to $8$, and are suitable for our purposes.

Note also, that the default value for `num_neighbors` is `0`. Typically, when using `s_map` to test for nonlinear behavior, we allow all points in the reconstruction to be used, subject only to the weighting based on distance. By using `0` for `num_neighbors` (an otherwise nonsensical value), we let the program know to use all nearest neighbors.

```{r}
smap_output <- s_map(ts, lib, pred, E = 5)
```

Again, the results are a simple data.frame with columns for each of the model parameters and forecast statistics, and rows for each run of the model. In this case, there is one run for each value of $\theta$, so we can simply plot $\theta$ against $\rho$:

```{r}
par(mar = c(4,4,1,1))
plot(smap_output$theta, smap_output$rho, type = "l", 
     xlab = "Nonlinearity (theta)", ylab = "Forecast Skill (rho)")
```

## Multivariate Models

Instead of creating an attractor by taking lags of a single time series, it is possible to combine lags from different time series, as long as they are all observed from the same system. Here, forecasts can be made using the `block_lnlp` function, which can be set to use either of the **simplex projection** or **s-map** algorithms.

For `block_lnlp`, the main data input is expected to be a matrix or data.frame of the time series observations, where each column is a separate time series and each row represents the variables observed at the same time. In addition to the typical arguments for `simplex` or `s_map`, `block_lnlp` contains arguments to specify which column is to be forecast (the `target_column` argument) as well as which columns to use to construct the attractor (the `columns` argument). In both cases, either a numerical index or the column name can be given.

Note that if lagged coordinates are intended to be used, they need to be manually created as separate columns in the matrix or data.frame.

We begin by loading an example dataset of time series and lags from a coupled 3-species model system. Here, the `block_3sp` variable is a 10-column data.frame with 1 column for time, and 3 columns for each of the variables (unlagged, t-1, and t-2 lags).

```{r}
data(block_3sp)
head(block_3sp)
```

In order to correctly index into columns, `block_lnlp` has an option to indicate that the first column is actually a time index. When `first_column_time` is set to `TRUE`, a value of `1` for `target_column` now points to the first **data** column in the data.frame, as opposed to the time column (the `columns` is similarly indexed).

```{r}
lib <- c(1, NROW(block_3sp))
pred <- c(1, NROW(block_3sp))

block_lnlp_output <- block_lnlp(block_3sp, lib = lib, pred = pred, 
                                columns = c(1,2,4), target_column = 1, 
                                stats_only = FALSE, first_column_time = TRUE)
```

We can also run the same model by referring to the names of the columns directly.

```{r}
block_lnlp_output <- block_lnlp(block_3sp, lib = lib, pred = pred, 
                                columns = c("x_t", "x_t-1", "y_t"), target_column = "x_t", 
                                stats_only = FALSE, first_column_time = TRUE)
```

Note that we did not specify a value for the `tp` parameter. Here, the default value of `1` means that the program will use the specified model to predict the target variable 1 time step into the future (based on the row-structure of the input data). In some cases, the data may already be processed into a format where one wants to predict a variable that has already been aligned correctly. In that case, one can set `tp = 0` when calling `block_lnlp`.

By setting `stats_only` to `FALSE`, we get back a list with the full model output. Only 1 model was run, so the output is a list with 1 element. To extract the raw predictions, we can go into the `model_output` variable and pull out the observed and predicted values, plotting them to see how well the model fit relative to the expected 1:1 line.

```{r}
observed <- block_lnlp_output[[1]]$model_output$obs
predicted <- block_lnlp_output[[1]]$model_output$pred

par(mar = c(4,4,1,1), pty = "s")
plot_range <- range(c(observed, predicted), na.rm = TRUE)
plot(observed, predicted, 
     xlim = plot_range, ylim = plot_range, 
     xlab = "Observed", ylab = "Predicted")
abline(a = 0, b = 1, lty = 2, col = "blue")
```

## Convergent Cross Mapping

**Convergent Cross Mapping** (**CCM**) is a technique to identify causality based on the idea of attractor reconstruction. In essence, if $x$ has a causal influence on $y$, then the reconstructions based on $x$ and $y$ should be diffeomorphic, and there should be a mapping from the reconstruction based on $y$ to the reconstruction based on $x$. Furthermore, with longer time series, the reconstructions will be more precise, which should cause the cross mapping skill to converge as time series length increases.

The `ccm` function is an easy way to compute cross map skill for multiple subsamples of different libraries. In the following example, we use CCM to identify causality between anchovy landings in California and Newport Pier sea-surface temperature. 

Here, we use a previously identified value of `3` for the embedding dimension. We set `lib_sizes` (the number of library vectors) to vary from `10` to `80` in steps of `10`. Setting `num_samples` to `100` means that 100 different library samples will be generated, by random sampling (`random_libs = TRUE` by default) from the possible vectors with replacement (`replace = TRUE` by default). 

```{r}
data(sardine_anchovy_sst)
anchovy_xmap_sst <- ccm(sardine_anchovy_sst, E = 3, 
                            lib_column = "anchovy", target_column = "np_sst", 
                            lib_sizes = seq(10, 80, by = 10), num_samples = 100, 
                            silent = TRUE)
sst_xmap_anchovy <- ccm(sardine_anchovy_sst, E = 3, 
                            lib_column = "np_sst", target_column = "anchovy", 
                            lib_sizes = seq(10, 80, by = 10), num_samples = 100, 
                            silent = TRUE)
```

The output from CCM is a data.frame with statistics for each model run (in thise case, 100 models at each of 8 library sizes = 800 rows). Because we cross map using multiple libraries at each library size, we'd like to aggregate the results and plot the average cross map skill at each library size. Because average cross map skill less than $0$ is noninformative, we filter out negative values when plotting.

```{r, warning=FALSE}
a_xmap_t_means <- ccm_means(anchovy_xmap_sst)
t_xmap_a_means <- ccm_means(sst_xmap_anchovy)

par(mar = c(4,4,1,1))
plot(a_xmap_t_means$lib_size, pmax(0, a_xmap_t_means$rho), type = "l", col = "darkolivegreen", 
     xlab = "Library Size", ylab = "Cross Map Skill (rho)", ylim = c(0, 0.4))
lines(t_xmap_a_means$lib_size, pmax(0, t_xmap_a_means$rho), col = "blue")
legend(x = "topleft", legend = c("anchovy xmap SST", "SST xmap anchovy"), 
       col = c("darkolivegreen", "blue"), lwd = 1, inset = 0.02)
```

# Applications

## Composite Time Series

In some cases, we may have multiple time series that can serve as spatial or ecological replicates. To treat these time series as replicates when applying EDM, we want to combine the data together into a single composite time series. Because the scale may differ across time series, we typically apply a normalization routine to linearly transform each time series to have mean = 0 and variance = 1 before concatenating. 

```{r}
data(sockeye_returns)

# separate time column from data
time <- sockeye_returns$year
sockeye_returns <- sockeye_returns[,-1]

# normalize each time series
n <- NCOL(sockeye_returns)
for(j in 1:n)
{
    sockeye_returns[,j] <- (sockeye_returns[,j] - mean(sockeye_returns[,j])) / sd(sockeye_returns[,j])
}

# make composite time series
composite_ts <- data.frame(year = time, 
                           returns = stack(sockeye_returns)$value)
```

Before applying EDM, however, we want to make sure that EDM will properly recognize the different time series segments as being different, so that lagged vectors are not constructed that contain coordinates spanning multiple time series. This is simply handled by constructing the lib and pred so that the first column designates the start of each time series segment, and the second column designates the end.

```{r}
# make composite library
segments <- cbind(seq(from = 1, by = NROW(sockeye_returns), length.out = n), 
                  seq(from = NROW(sockeye_returns), by = NROW(sockeye_returns), length.out = n))
composite_lib <- segments[1:5,]
composite_pred <- segments[6:9,]
```

We can then use the **rEDM** functions as normal:

```{r}
simplex_output <- simplex(composite_ts, composite_lib, composite_pred)
par(mar = c(4,4,1,1))
plot(simplex_output$E, simplex_output$rho, type = "l", 
     xlab = "Embedding Dimension (E)", ylab = "Forecast Skill (rho)")
```

```{r}
smap_output <- s_map(composite_ts, composite_lib, composite_pred, E = 8)
par(mar = c(4,4,1,1))
plot(smap_output$theta, smap_output$rho, type = "l", 
     xlab = "Nonlinearity (theta)", ylab = "Forecast Skill (rho)")
```

## Scenario Exploration

# Diagnostic Tests

## Prediction Decay
## Nonlinearity Tests Using Surrogate Data
## Cross Mapping Convergence


# Acknowledgements

**rEDM** is the latest incarnation of EDM code. Past versions have been developed by George Sugihara, Alan Trombla, Richard Penner, Victor Wong, Martin Casdagli, Mohsen Azarbayejani, Ava Pierce, Jennifer Trezzo, and Hao Ye.

# References
